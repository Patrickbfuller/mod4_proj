{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn_pandas import DataFrameMapper, cross_val_score\n",
    "from sklearn_pandas.pipeline import Pipeline\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('prepped_data.json').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>weekday_posted</th>\n",
       "      <th>hour_posted</th>\n",
       "      <th>log_score</th>\n",
       "      <th>log_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300</td>\n",
       "      <td>1588</td>\n",
       "      <td>21720</td>\n",
       "      <td>China Killing Prisoners To Harvest Organs For ...</td>\n",
       "      <td>2019-06-19 11:49:08</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>9.985989</td>\n",
       "      <td>7.370237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>240</td>\n",
       "      <td>402</td>\n",
       "      <td>2661</td>\n",
       "      <td>Muslim family dragged out of Belgian embassy i...</td>\n",
       "      <td>2019-06-19 12:05:31</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>7.886457</td>\n",
       "      <td>5.996477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>660</td>\n",
       "      <td>3320</td>\n",
       "      <td>46977</td>\n",
       "      <td>Women outperform men after Japan medical schoo...</td>\n",
       "      <td>2019-06-19 05:51:44</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10.757413</td>\n",
       "      <td>8.107723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>360</td>\n",
       "      <td>202</td>\n",
       "      <td>1474</td>\n",
       "      <td>MH17 crash: Investigators 'to charge four with...</td>\n",
       "      <td>2019-06-19 10:50:51</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>7.295735</td>\n",
       "      <td>5.308317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>660</td>\n",
       "      <td>1336</td>\n",
       "      <td>2665</td>\n",
       "      <td>Iranian official calls on world to unite again...</td>\n",
       "      <td>2019-06-19 05:09:15</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>7.887959</td>\n",
       "      <td>7.197443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  num_comments  score  \\\n",
       "0  300          1588  21720   \n",
       "1  240           402   2661   \n",
       "2  660          3320  46977   \n",
       "3  360           202   1474   \n",
       "4  660          1336   2665   \n",
       "\n",
       "                                                text           timestamp  \\\n",
       "0  China Killing Prisoners To Harvest Organs For ... 2019-06-19 11:49:08   \n",
       "1  Muslim family dragged out of Belgian embassy i... 2019-06-19 12:05:31   \n",
       "2  Women outperform men after Japan medical schoo... 2019-06-19 05:51:44   \n",
       "3  MH17 crash: Investigators 'to charge four with... 2019-06-19 10:50:51   \n",
       "4  Iranian official calls on world to unite again... 2019-06-19 05:09:15   \n",
       "\n",
       "   weekday_posted  hour_posted  log_score  log_comments  \n",
       "0               2           11   9.985989      7.370237  \n",
       "1               2           12   7.886457      5.996477  \n",
       "2               2            5  10.757413      8.107723  \n",
       "3               2           10   7.295735      5.308317  \n",
       "4               2            5   7.887959      7.197443  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['text','age','weekday_posted','hour_posted']]\n",
    "y = df['log_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2019)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>age</th>\n",
       "      <th>weekday_posted</th>\n",
       "      <th>hour_posted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4867</th>\n",
       "      <td>Donald Trump Jr. on Sunday claimed CNN is cove...</td>\n",
       "      <td>1440</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>Oxfam warns of the \"worst cholera outbreak in ...</td>\n",
       "      <td>1440</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2819</th>\n",
       "      <td>Exposure to weed killing products increases ri...</td>\n",
       "      <td>1440</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>Hong Kong protesters demand China be held to a...</td>\n",
       "      <td>660</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>Austrian Government Seeks to Eliminate Interne...</td>\n",
       "      <td>180</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text   age  weekday_posted  \\\n",
       "4867  Donald Trump Jr. on Sunday claimed CNN is cove...  1440               0   \n",
       "1395  Oxfam warns of the \"worst cholera outbreak in ...  1440               5   \n",
       "2819  Exposure to weed killing products increases ri...  1440               3   \n",
       "567   Hong Kong protesters demand China be held to a...   660               0   \n",
       "1444  Austrian Government Seeks to Eliminate Interne...   180               4   \n",
       "\n",
       "      hour_posted  \n",
       "4867            4  \n",
       "1395           11  \n",
       "2819           11  \n",
       "567             0  \n",
       "1444           10  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting Embeddings from GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = X_train.text\n",
    "data = headers.map(word_tokenize).values\n",
    "total_vocabulary = set(word for headline in data for word in headline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = {}\n",
    "with open('/Users/patrickfuller/flatiron/glove/glove.6B.50d.txt', 'rb') as f:\n",
    "    for line in f:\n",
    "        parts = line.split()\n",
    "        word = parts[0].decode('utf-8')\n",
    "        if word in total_vocabulary:\n",
    "            vector = np.array(parts[1:], dtype=np.float32)\n",
    "            glove[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LETS BORROW SOME LOVELY CODE FROM OUR CURRICULUM!\n",
    "class W2vVectorizer(object):\n",
    "    \n",
    "    def __init__(self, w2v):\n",
    "        # takes in a dictionary of words and vectors as input\n",
    "        self.w2v = w2v\n",
    "        if len(w2v) == 0:\n",
    "            self.dimensions = 0\n",
    "        else:\n",
    "            self.dimensions = len(w2v[next(iter(glove))])\n",
    "    \n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "            \n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.w2v[w] for w in words if w in self.w2v]\n",
    "                   or [np.zeros(self.dimensions)], axis=0) for words in X])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = W2vVectorizer(glove)\n",
    "ohe = OneHotEncoder(drop='first',categories='auto')\n",
    "ss = StandardScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = DataFrameMapper([\n",
    "    ('text', w2v),\n",
    "    (['age'], ss),\n",
    "    (['weekday_posted', 'hour_posted'], ohe),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(n_jobs=-1)\n",
    "rfr = RandomForestRegressor(n_jobs=1, n_estimators=100)\n",
    "gbr = GradientBoostingRegressor(n_estimators=100)\n",
    "knnr = KNeighborsRegressor(n_jobs=-1)\n",
    "regressors = [lr,rfr,gbr,knnr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MAE of the LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)is\n",
      "\t:6790.891015102855\n",
      "The MAE of the RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "                      oob_score=False, random_state=None, verbose=0,\n",
      "                      warm_start=False)is\n",
      "\t:6819.854030568219\n",
      "The MAE of the GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "                          learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='auto',\n",
      "                          random_state=None, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)is\n",
      "\t:6633.770062884442\n",
      "The MAE of the KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "                    weights='uniform')is\n",
      "\t:6922.4563426945015\n"
     ]
    }
   ],
   "source": [
    "for regressor in regressors:\n",
    "    pipe = Pipeline(steps=[\n",
    "        ('transform',mapper),\n",
    "        ('regressor', regressor)\n",
    "    ])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    preds = np.exp(pipe.predict(X_test))\n",
    "    print(f'The MAE of the {str(regressor)}'\n",
    "        f'\\n\\tis:{mean_absolute_error(np.exp(y_test),preds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = df['log_comments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y2_train, y2_test = train_test_split(X, y2, random_state=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MAE of the LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)\n",
      "\tis:568.3032034701123\n",
      "The MAE of the RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "                      oob_score=False, random_state=None, verbose=0,\n",
      "                      warm_start=False)\n",
      "\tis:553.4577578405839\n",
      "The MAE of the GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "                          learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='auto',\n",
      "                          random_state=None, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "\tis:543.3343767656875\n",
      "The MAE of the KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "                    weights='uniform')\n",
      "\tis:575.6672269579948\n"
     ]
    }
   ],
   "source": [
    "for regressor in regressors:\n",
    "    pipe = Pipeline(steps=[\n",
    "        ('transform',mapper),\n",
    "        ('regressor', regressor)\n",
    "    ])\n",
    "    pipe.fit(X_train, y2_train)\n",
    "    preds = np.exp(pipe.predict(X_test))\n",
    "    print(f'The MAE of the {str(regressor)}'\n",
    "        f'\\n\\tis:{mean_absolute_error(np.exp(y2_test),preds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=2000)\n",
    "\n",
    "mapper = DataFrameMapper([\n",
    "    ('text', w2v),\n",
    "    ('text', tfidf),       # Adding a second feature extraction on text\n",
    "    (['age'], ss),\n",
    "    (['weekday_posted', 'hour_posted'], ohe),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MAE of the LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)\n",
      "\tis:14254.068314102651\n",
      "The MAE of the RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "                      oob_score=False, random_state=None, verbose=0,\n",
      "                      warm_start=False)\n",
      "\tis:6755.867641844939\n",
      "The MAE of the GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "                          learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='auto',\n",
      "                          random_state=None, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "\tis:6675.5394901238315\n",
      "The MAE of the KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "                    weights='uniform')\n",
      "\tis:6951.999131503912\n"
     ]
    }
   ],
   "source": [
    "for regressor in regressors:\n",
    "    pipe = Pipeline(steps=[\n",
    "        ('transform',mapper),\n",
    "        ('regressor', regressor)\n",
    "    ])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    preds = np.exp(pipe.predict(X_test))\n",
    "    print(f'The MAE of the {str(regressor)}'\n",
    "        f'\\n\\tis:{mean_absolute_error(np.exp(y_test),preds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MAE of the LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)\n",
      "\tis:1023.902251612284\n",
      "The MAE of the RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "                      oob_score=False, random_state=None, verbose=0,\n",
      "                      warm_start=False)\n",
      "\tis:537.9441001311949\n",
      "The MAE of the GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "                          learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='auto',\n",
      "                          random_state=None, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "\tis:532.9491219923372\n",
      "The MAE of the KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "                    weights='uniform')\n",
      "\tis:578.3575327123231\n"
     ]
    }
   ],
   "source": [
    "for regressor in regressors:\n",
    "    pipe = Pipeline(steps=[\n",
    "        ('transform',mapper),\n",
    "        ('regressor', regressor)\n",
    "    ])\n",
    "    pipe.fit(X_train, y2_train)\n",
    "    preds = np.exp(pipe.predict(X_test))\n",
    "    print(f'The MAE of the {str(regressor)}'\n",
    "        f'\\n\\tis:{mean_absolute_error(np.exp(y2_test),preds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=4000)\n",
    "\n",
    "mapper = DataFrameMapper([\n",
    "    ('text', w2v),\n",
    "    ('text', tfidf),       # Adding a second feature extraction on text\n",
    "    (['age'], ss),\n",
    "    (['weekday_posted', 'hour_posted'], ohe),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MAE of the LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)\n",
      "\tis:45211509309.16554\n",
      "The MAE of the RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "                      oob_score=False, random_state=None, verbose=0,\n",
      "                      warm_start=False)\n",
      "\tis:6773.908494301302\n",
      "The MAE of the GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "                          learning_rate=0.1, loss='ls', max_depth=3,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                          n_iter_no_change=None, presort='auto',\n",
      "                          random_state=None, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "\tis:6658.66076261992\n",
      "The MAE of the KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "                    weights='uniform')\n",
      "\tis:6952.321071372296\n"
     ]
    }
   ],
   "source": [
    "for regressor in regressors:\n",
    "    pipe = Pipeline(steps=[\n",
    "        ('transform',mapper),\n",
    "        ('regressor', regressor)\n",
    "    ])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    preds = np.exp(pipe.predict(X_test))\n",
    "    print(f'The MAE of the {str(regressor)}'\n",
    "        f'\\n\\tis:{mean_absolute_error(np.exp(y_test),preds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
